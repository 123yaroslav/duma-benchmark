(DUMA-bench - working name: DUMA - Dual-control-User-Multi-Agent  Interaction Benchmark) 
Dual-control framework for benchmark vulnerabilities in multi-agent LLM systems.
Ivan Aleksandrov
Keywords: Benchmark; Multi-Agent Systems; LLMs; Dual-Control; Inter-Agent Coordination; Alignment; Reliability.

Topic Description:
   Existing benchmarks for agentic systems1,2, including the breakthrough tau family3,4, focus primarily on the interaction between a single agent and a user. However, modern systems increasingly involve multiple agents that must interact with each other and with several users under conditions of partial observability, dynamic role distribution, and task delegation5.

    The experience of τ²-bench4 has shown that even requiring an agent to coordinate with an active user can cause a performance drop, revealing communication as a major bottleneck. In multi-agent scenarios, this problem becomes even more complex:
agents must exchange information and form joint strategies through limited communication channels;
they need to delegate subtasks and verify the correctness of execution by others;
systems face conflicts of interest, trust failures, or exploitation vulnerabilities, creating new points of failure;
overall efficiency depends not only on each agent’s cognitive abilities but also on its capacity for cooperation, negotiation, and adaptive behavior.
The goal of this paper is to introduce the conceptual framework of DUMA-bench, a new evaluation standard that extends benchmarking to N-player multi-agent systems.
This benchmark aims to formalize and assess performance in contexts involving:
strategic inter-agent coordination,
adaptive delegation and oversight,
conflict resolution and responsibility allocation,
and system robustness to internal failures or manipulations.
DUMA-bench represents a step toward more realistic and comprehensive evaluation of AI architectures, reflecting real-world settings where intelligence emerges not only from individual reasoning, but also from mutual understanding and collective rationality.
Introduction
The rapid expansion of large language model (LLM) capabilities has catalyzed a shift from isolated, single-agent systems toward complex, distributed agentic architectures deployed in real-world workflows. Early evaluations of LLM-based agents primarily assessed autonomous tool use and instruction following, assuming centralized control and full observability7,8. While such benchmarks were instrumental in characterizing isolated reasoning abilities, they fail to capture the interaction dynamics, coordination requirements, and failure modes that emerge when multiple agents share control over a dynamic environment.
Recent research has demonstrated that even minimal multi-actor interaction introduces significant instability in agent performance. The τ-bench3 framework modeled the user as an active, state-altering participant rather than a passive instruction source, while τ²-bench4 extended this into a dual-control setting, formalizing the environment as a two-party Decentralized POMDP6 (Dec-POMDP) and showing that shared control induces a performance degradation of up to 25 percentage points for frontier LLMs such as o4-mini4. These results highlight a central challenge: communication and coordination, not pure reasoning - become the dominant bottlenecks in agent performance.
However, dual-control settings remain fundamentally bilateral. Modern agentic systems increasingly operate in N-player, multi-agent ecosystems, where several heterogeneous agents and multiple users interact under asymmetric information, limited communication bandwidth, and dynamically shifting roles. Environments such as Agent Dojo9 demonstrate the value of controlled multi-agent evaluation for tool use and adversarial interactions, but remain focused on pairwise or team-vs-environment configurations rather than general decentralized cooperation and oversight.
Multi-agent systems literature has long established that scaling from two-party to N-party environments introduces qualitatively new challenges, including joint policy factorization, credit assignment, coordination equilibria, communication constraints, and coalition instability6. In LLM-driven systems, these challenges are amplified by the stochasticity of natural language communication, implicit reasoning processes, and vulnerability to adversarial manipulation or misaligned delegation. As shown in recent work on multi-agent LLM simulations10, even simple cooperative tasks can lead to brittle coordination, role confusion, or emergent failure cascades.
To address these gaps, we introduce DUMA-bench (Dual-control-User-Multi-Agent Interaction Benchmark), a framework that generalizes dual-control evaluation to N-player LLM-based multi-agent systems. DUMA-bench extends the Dec-POMDP formalism to support:
• multi-party coordination under uncertainty, where agents must maintain coherence despite partial, inconsistent, or adversarially manipulated information;
• adaptive task delegation and hierarchical oversight, testing whether agents can allocate responsibilities, verify execution, and detect deviations;
• strategic negotiation and distributed decision-making, including cooperative and competitive equilibria;
• resilience to systemic vulnerabilities, including misinformation propagation, malicious delegation chains, trust collapse, sybil-like infiltration, and resource competition.
A key innovation of DUMA-bench is its inclusion of vulnerability-oriented evaluation scenarios, enabling stress-testing of LLM-based multi-agent systems across domains such as cybersecurity, supply-chain coordination, collaborative planning, and information integrity. 
By bridging the gap between dual-control agent evaluations and fully decentralized, multi-agent intelligence, DUMA-bench provides a foundation for analyzing collective rationality, coordination stability, and alignment robustness in distributed LLM systems. The resulting framework captures emergent behaviors that cannot be observed in isolated agent testing and establishes a new standard for evaluating real-world multi-agent AI deployments.

Related Work:
Autonomous and Single-Control Benchmarks3.
Earlier tool-use benchmarks evaluated agents in monopoly-control settings, where the agent was the sole actor capable of modifying the environment. In these setups, the user was treated as either a passive information source or a static part of the environment, rather than an active participant capable of altering the shared state. 
Dual-Control Frameworks (τ²-bench)4.
The τ²-bench framework introduced shared control between an AI agent and a user, formalizing the interaction as a two-party Dec-POMDP6. This work demonstrated that the agent’s ability to guide, instruct, and synchronize with an active user is a major point of failure - often producing substantial performance degradation relative to solo execution. τ²-bench thereby established the methodological foundation for evaluating coordination under partial observability and asymmetric control.
Adversarial Interaction and Robustness Benchmarks (Agent Dojo)9.
Agent Dojo extends evaluation beyond cooperative setups by introducing structured adversarial scenarios such as prompt-injection attacks, corrupted tool outputs, and malicious environment manipulations. Unlike single-agent tool-use evaluations, Agent Dojo probes agents’ resilience to intentional interference and systemic vulnerabilities, demonstrating that modern LLM agents often fail even under mild adversarial pressure. This benchmark highlights the need for evaluating robustness, trust calibration, and defensive strategies within both single-agent and multi-agent contexts.
Multi-Agent Coordination Benchmarks (REALM-Bench)11.
REALM-Bench targets multi-agent coordination in logistics, planning, and decentralized scheduling domains. It stresses agents' abilities to share information, form joint policies, manage role specialization, and maintain stable coordination under dynamic disruptions. While REALM-Bench does not model user involvement or dual-control dynamics, it provides the clearest evidence that multi-agent tasks introduce new failure modes - such as misaligned role allocation, communication breakdowns, and unstable negotiation patterns - that are not captured by single-agent or two-player benchmarks. These observations motivate the need for evaluation frameworks that combine multi-agent coordination, dual-control interaction, and vulnerability assessment, as pursued in DUMA-bench.



References
1.	Liu, X. et al. AgentBench: Evaluating LLMs as Agents. Preprint at https://doi.org/10.48550/arXiv.2308.03688 (2025). 
2.	Zhang, H. et al. Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents. Preprint at https://doi.org/10.48550/arXiv.2410.02644 (2025). 
3.	Yao, S., Shinn, N., Razavi, P. & Narasimhan, K. $τ$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains. Preprint at https://doi.org/10.48550/arXiv.2406.12045 (2024). 
4.	Barres, V., Dong, H., Ray, S., Si, X. & Narasimhan, K. $τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment. Preprint at https://doi.org/10.48550/arXiv.2506.07982 (2025). 
5.	Jin, W. et al. A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives. Preprint at https://doi.org/10.48550/arXiv.2503.13415 (2025). 
6.	Amato, C., Chowdhary, G., Geramifard, A., Ure, N. K. & Kochenderfer, M. J. Decentralized control of partially observable Markov decision processes. in 52nd IEEE Conference on Decision and Control 2398–2405 (IEEE, Firenze, 2013). doi:10.1109/CDC.2013.6760239. 
7.	Qin, Y. et al. Tool Learning with Foundation Models. ACM Comput. Surv. 57, 1–40 (2025). 
8.	Schick, T. et al. Toolformer: Language models can teach themselves to use tools. Adv. Neural Inf. Process. Syst. 36, 68539–68551 (2023). 
9.	Debenedetti, E. et al. Agentdojo: A dynamic environment to evaluate prompt injection attacks and defenses for llm agents. Adv. Neural Inf. Process. Syst. 37, 82895–82920 (2024). 
10.	Park, J. S. et al. Generative Agents: Interactive Simulacra of Human Behavior. in Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology 1–22 (ACM, San Francisco CA USA, 2023). doi:10.1145/3586183.3606763. 
11.	Geng, L. & Chang, E. Y. Realm-bench: A real-world planning benchmark for llms and multi-agent systems. ArXiv Prepr. ArXiv250218836 https://www.researchgate.net/profile/Edward-Chang-22/publication/389279327_REALM-Bench_A_Real-World_Planning_Benchmark_for_LLMs_and_Multi-Agent_Systems/links/67bcd8f6f5cb8f70d5be8cf3/REALM-Bench-A-Real-World-Planning-Benchmark-for-LLMs-and-Multi-Agent-Systems.pdf (2025). 

